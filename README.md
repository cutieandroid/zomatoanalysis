# zomatoanalysis




About the project:
In this project, you will be working on a real-world dataset of zomato, one of the most used food ordering platform. This project aims on cleaning the dataset, analyze the given dataset, and mining informational quality insights. This project also involves visualizing the data to better understand the restaurantâ€™s performance

Project Description: 

This project will help you understand how a real-world database is analyzed using SQL, how to get maximum available insights from the dataset, pre-process the data using python for better upcoming performance, how a structured query language helps us retrieve useful information from the database, and visualize the data with the power bi tool.
The Project will consist of 2 modules:
Module 1: Pre-processing, Analyzing data using Python and SQL.
Module 2: Visualizing data using Power bi.

Prerequisites for the Project (mandatory): 

1.	SQL (MYSQL)
2.	POWER BI/ Tableau
3.	Excel
4.	Python

Module 1
 Pre-processing, Analyzing data using SQL

In this module, you will query the dataset using structured query language to gain insights from the database. The problem statements to be solved will be provided to you and you need to provide the solution for the same using your logic. Different concepts of SQL will be used in this process such as aggregating the data, grouping the data, ordering the data, etc. Module 1 consists of subtasks which are as follows

 Pre-processing the data

Data Pre-processing is one of the important steps in data analytics because data that is not processed can lead to different unwanted results when the data will be used for further applications. This task includes sub-tasks such as handling null values, deletion or transformation of irrelevant values, datatype transformation, removing duplicates, etc. The tasks to be performed for cleaning the data set are given below:


#task1: remove unwanted columns

#task2: rename columns,  only these columns are allowed in the dataset
1.	Id
2.	Name
3.	online_order
4.	book_table
5.	rating
6.	votes
7.	location
8.	rest_type
9.	dish_liked
10.	cuisines
11.	approx_cost
12.	type






#task3: handle  null values of each column

#task4: find duplicates in the dataset

#task5 removing irrelevant text from all the columns

#task6: check for unique values in each column and handle the irrelevant values

#task7: remove the unknown character from the dataset

#task8: export the cleaned dataset

#task9: perform deduplication task in excel for identical rows

#task10: Use this final dataset and upload it on the provided database for performing analysis in  MySQL
